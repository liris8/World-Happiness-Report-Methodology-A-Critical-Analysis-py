{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Factory\n",
    "In this notebook, we process the data to be used in our study. We merge the World Happiness Report data together with the Our World in Data data of mental health disorders, in particular, depression and anxiety. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "file_happiness = \"Data Bases/WHR-Full.xls\"\n",
    "file_metal_health_illnesses = \"Data Bases/Mental health disorders.xlsx\"\n",
    "dfh = pd.read_excel(file_happiness)\n",
    "dfsv = pd.read_excel(file_metal_health_illnesses)\n",
    "\n",
    "dfh.loc[dfh['Year'] == 2005, 'Generosity'] = np.nan # Only one value is redundant, so we remove it\n",
    "# dfh[dfh['Year'] == 2005]['Generosity'] # Sanity check to see if the value is removed\n",
    "\n",
    "\n",
    "dfsv = dfsv[dfsv['Year'] >= 2005] # Filter out years before 2005\n",
    "dfsv = dfsv[dfsv['Country'] != 'China'] # In WHR data, China is splitted into China and Hong Kong, so we filter out China to avoid mismatching\n",
    "\n",
    "# dfsv[dfsv['Country'] == 'China'] # Sanity check to see if China is filtered out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the names by acronyms\n",
    "acronyms_h = {'Life Ladder': 'LL', 'Log GDP per capita': 'GDP', 'Social support': 'SS', 'Healthy life expectancy at birth': 'HLE', 'Freedom to make life choices': 'FMC', 'Generosity': 'G', 'Perceptions of corruption': 'PC', 'Positive affect': 'PA', 'Negative affect': 'NA'}\n",
    "dfh = dfh.rename(columns=acronyms_h)\n",
    "\n",
    "\n",
    "acronyms_sv = {'Depression': 'D', 'Anxiety': 'A'}\n",
    "dfsv = dfsv.rename(columns=acronyms_sv)\n",
    "\n",
    "# dfh\n",
    "# dfsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'China',\n",
       " 'Congo (Brazzaville)',\n",
       " 'Congo (Kinshasa)',\n",
       " 'Hong Kong S.A.R. of China',\n",
       " 'Ivory Coast',\n",
       " 'Kosovo',\n",
       " 'Somaliland region',\n",
       " 'State of Palestine',\n",
       " 'Taiwan Province of China',\n",
       " 'Turkiye'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def countries_differences(df1, df2):\n",
    "    # Extracting country names from both datasets\n",
    "    countries1 = df1['Country'].unique()\n",
    "    countries2 = df2['Country'].unique()\n",
    "\n",
    "    # Converting to sets for easier comparison\n",
    "    set_countries1 = set(countries1)\n",
    "    set_countries2 = set(countries2)\n",
    "\n",
    "    # Finding countries that are in one set but not the other\n",
    "    countries_only_in_wrh23 = set_countries1 - set_countries2\n",
    "    countries_only_in_sv = set_countries2 - set_countries1\n",
    "\n",
    "    # Finding common countries with potential different spellings\n",
    "    common_countries = set_countries1.intersection(set_countries2)\n",
    "    \n",
    "    return countries_only_in_wrh23, countries_only_in_sv, common_countries\n",
    "\n",
    "countries_only_in_wrh23, countries_only_in_sv, common_countries = countries_differences(dfh, dfsv)\n",
    "\n",
    "countries_only_in_wrh23\n",
    "# countries_only_in_sv\n",
    "# common_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'China', 'Hong Kong S.A.R. of China', 'Kosovo', 'Somaliland region'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the mapping of country names from the sv dataset to the wrh23 dataset\n",
    "def country_mapping(df_to_change, country_mapping):\n",
    "    # Create a dictionary from the mapping for efficient replacement\n",
    "    country_dict = {old_name: new_name for new_name, old_name in country_mapping}\n",
    "\n",
    "    # Replace the country names in the 'country' column of dfsv\n",
    "    df_to_change['Country'] = df_to_change['Country'].replace(country_dict)\n",
    "\n",
    "    return df_to_change\n",
    "\n",
    "mapping = [\n",
    "    (\"Congo (Brazzaville)\", \"Congo\"),\n",
    "    (\"Congo (Kinshasa)\", \"Democratic Republic of Congo\"),\n",
    "    (\"Ivory Coast\", \"Cote d'Ivoire\"),\n",
    "    (\"State of Palestine\", \"Palestine\"),\n",
    "    (\"Taiwan Province of China\", \"Taiwan\"),\n",
    "    (\"Turkiye\", \"Turkey\")\n",
    "]\n",
    "\n",
    "dfsv = country_mapping(dfsv, mapping)\n",
    "\n",
    "# Sanity check\n",
    "countries_only_in_wrh23, countries_only_in_sv, common_countries = countries_differences(dfh, dfsv)\n",
    "countries_only_in_wrh23 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two datasets\n",
    "final_df = dfh.merge(dfsv, on=['Country', 'Year'], how='left') # Left join to keep all the data from the happiness dataset\n",
    "final_df.to_excel(\"Data Bases/WHR-Full-Merged.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
